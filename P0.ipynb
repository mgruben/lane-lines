{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** \n",
    "***\n",
    "In this project, you will use the tools you learned about in the lesson to identify lane lines on the road.  You can develop your pipeline on a series of individual images, and later apply the result to a video stream (really just a series of images). Check out the video clip \"P0_example1.mp4\" (also contained in this repository) to see what the output should look like. \n",
    "\n",
    "Let's have a look at our first image called 'test_images/solidWhiteRight.jpg'.  Run the 2 cells below (hit Shift-Enter or the \"play\" button above) to display the image.\n",
    "\n",
    "**Note** If, at any point, you encounter frozen display windows or other confounding issues, you can always start again with a clean slate by going to the \"Kernel\" menu above and selecting \"Restart & Clear Output\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The tools you have are color selection, region of interest selection, grayscaling, Gaussian smoothing, Canny Edge Detection and Hough Tranform line detection.  You  are also free to explore and try other techniques that were not presented in the lesson.  Your goal is piece together a pipeline to detect the lines in the image, and draw them onto the image for display (as below).  Once you have a working pipeline, try it out on the video stream below.**\n",
    "\n",
    "---\n",
    "\n",
    "<figure>\n",
    " <img src=\"laneLines_thirdPass.jpg\" width=\"480\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output image should look like this (more or less) after line detection </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading in an image\n",
    "image = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "#printing out some stats and plotting\n",
    "print('This image is:', type(image), 'with dimensions:', image.shape)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that in the above image, the vertices of interest appear to be:\n",
    "(100, 540), (480, 300), and (900, 540)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some OpenCV functions (beyond those introduced in the lesson) that might be useful for this project are:**\n",
    "\n",
    "`cv2.inRange()` for color selection  \n",
    "`cv2.fillPoly()` for regions selection  \n",
    "`cv2.line()` to draw lines on an image given endpoints  \n",
    "`cv2.addWeighted()` to coadd / overlay two images\n",
    "`cv2.cvtColor()` to grayscale or change color\n",
    "`cv2.imwrite()` to output images to file  \n",
    "`cv2.bitwise_and()` to apply a mask to an image\n",
    "\n",
    "**Check out the OpenCV documentation to learn about these and discover even more awesome functionality!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions to help get you started. They should look familiar from the lesson!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_noise(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    Draws `lines` with `color` and `thickness`.\n",
    "    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    \"\"\"\n",
    "    if lines == None:\n",
    "        return\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros(img.shape, dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images\n",
    "\n",
    "Now you should build your pipeline to work on the images in the directory \"test_images\"  \n",
    "**You should make sure your pipeline works well on these images before you try the videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\"test_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that I added two `challenge` jpgs for use in the optional part of this assignment.  They will be ignored until that part.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run your solution on all test_images and make copies into the test_images directory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Region of Interest\n",
    "First, we'll want to ensure that we're defining our region of interest correctly.\n",
    "The below code should help to mask off only the area of the image (and later, video) that we'll care about processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vertices from above\n",
    "vertices = np.array([[(100, 540), (440, 320), (520, 320), (900, 540)]])\n",
    "masked_image = region_of_interest(image, vertices)\n",
    "\n",
    "#printing out some stats and plotting\n",
    "print('The masked image is:', type(masked_image), 'with dimensions:', masked_image.shape)\n",
    "plt.imshow(masked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Canny Transform\n",
    "Next, we'll want to ensure that we're filtering out everything we can except for the lane lines themselves.  \n",
    "This isn't always possible, but the more we can successfully filter out noise, the easier it will be to draw the Hough lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "canny_image = canny(image, 255, 255)\n",
    "\n",
    "#printing out some stats and plotting\n",
    "print('The Canny-Transformed image is:', type(canny_image), 'with dimensions:', canny_image.shape)\n",
    "plt.imshow(canny_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From repeated trials with different `low_threshold` and `high_threshold` values, it would appear that using `255, 255` filters out most of the noise while leaving the existing lane lines visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing the Hough Lines\n",
    "First off, let's combine the results of the above two sections into a single image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_canny_image = region_of_interest(canny_image, vertices)\n",
    "\n",
    "#printing out some stats and plotting\n",
    "print('The masked, Canny-Transformed image is:', type(masked_canny_image),\n",
    "      'with dimensions:', masked_canny_image.shape)\n",
    "plt.imshow(masked_canny_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're looking at just the lane lines, as identified by the Canny transformation. Cool!  \n",
    "We'll use this image to draw the Hough lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply a Gaussian Noise filter, or else the lines are more difficult to detect\n",
    "gaussian_image = gaussian_noise(masked_canny_image, 5)\n",
    "\n",
    "# Draw the Hough Lines\n",
    "hough_image = hough_lines(gaussian_image, rho = 1, theta = np.pi / 180, threshold = 50,\n",
    "                          min_line_len = 100, max_line_gap = 150)\n",
    "# See, e.g., http://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.html,\n",
    "# especially 4. Probabilistic Hough Line Transform\n",
    "\n",
    "#printing out some stats and plotting\n",
    "print('The image with Hough Lines drawn is:', type(hough_image), 'with dimensions:', hough_image.shape)\n",
    "plt.imshow(hough_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll superimpose these Hough Lines on our original image, so that the humans know that the car knows where the lane lines are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform the hough_image into the same channel space.\n",
    "# Or else, cv2.addWeighted will fail.\n",
    "hough_image_BGR = cv2.cvtColor(hough_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Make the Hough Lines pink, because I like pink.\n",
    "b,g,r = cv2.split(hough_image_BGR)\n",
    "g = 0 * g\n",
    "b * 0.5 * b\n",
    "hough_image_pink = cv2.merge((b, g, r))\n",
    "# See, e.g., http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.html\n",
    "\n",
    "# Superimpose the Hough Lines on the original image\n",
    "# Using the default parameters for α, β, and λ\n",
    "superimposed_image = weighted_img(hough_image_pink, image, α=0.8, β=1., λ=0.1)\n",
    "\n",
    "#printing out some stats and plotting\n",
    "print('The original image with Hough Lines superimposed is:', type(superimposed_image),\n",
    "      'with dimensions:', superimposed_image.shape)\n",
    "plt.imshow(superimposed_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we've got a good first try, let's build a pipeline and apply it to all the images in the `test_images` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # Apply the Canny Transform\n",
    "    canny_image = canny(image, 255, 255)\n",
    "\n",
    "    # Mask the Region of Interest\n",
    "    vertices = np.array([[(100, 540), (440, 325), (520, 325), (900, 540)]])\n",
    "    masked_canny_image = region_of_interest(canny_image, vertices)\n",
    "\n",
    "    # Apply a Gaussian Noise filter\n",
    "    gaussian_image = gaussian_noise(masked_canny_image, 5)\n",
    "\n",
    "    # Draw the Hough Lines\n",
    "    hough_image = hough_lines(gaussian_image, rho = 1, theta = np.pi / 180, threshold = 50,\n",
    "                          min_line_len = 100, max_line_gap = 150)\n",
    "\n",
    "    # Transform the hough_image into the same channel space.\n",
    "    # Or else, cv2.addWeighted will fail.\n",
    "    hough_image_BGR = cv2.cvtColor(hough_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Make the Hough Lines pink, because I like pink.\n",
    "    b,g,r = cv2.split(hough_image_BGR)\n",
    "    g = 0 * g\n",
    "    b * 0.5 * b\n",
    "    hough_image_pink = cv2.merge((b, g, r))\n",
    "    # See, e.g., http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.html\n",
    "\n",
    "    # Superimpose the Hough Lines on the original image\n",
    "    # Using the default parameters for α, β, and λ\n",
    "    superimposed_image = weighted_img(hough_image_pink, image, α=0.8, β=1., λ=0.1)\n",
    "\n",
    "    return superimposed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_list = os.listdir(\"test_images/\")\n",
    "for file in test_list:\n",
    "    if \"challenge\" in file:\n",
    "        continue\n",
    "    img = mpimg.imread('test_images/' + file)\n",
    "    print('This image is:', type(img), 'with dimensions:', img.shape)\n",
    "    after_img = process_image(img)\n",
    "    plt.figure()\n",
    "    plt.title(file)\n",
    "    plt.imshow(after_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, if you were successful you probably have the Hough line segments drawn onto the road, but what about identifying the full extent of the lane and marking it clearly as in the example video (P0_example1.mp4)?  Think about defining a line to run the full length of the visible lane based on the line segments you identified with the Hough Transform.  Modify your draw_lines function accordingly and try re-running your pipeline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slope Extension\n",
    "If our Hough Transform yields a line, it's probably a lane line.  As such, it almost certainly extends to the bottom of the frame.  Accordingly, draw lines that we find to the bottom of the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toBottom(shape, x1, y1, x2, y2, slope):\n",
    "    \"\"\"\n",
    "    Given x and y coordinates representing segments of a lane line,\n",
    "    and a tuple representing the dimensions of the given image,\n",
    "    returns the line which is drawn to the bottom of the image's frame\n",
    "    \"\"\"\n",
    "    bottom = shape[0]\n",
    "    right = shape[1]\n",
    "    if slope < 0:\n",
    "        # replace x1 and y1\n",
    "        y1 = bottom\n",
    "        x1 = int(x2 - (y2 - y1) / slope)\n",
    "    elif slope > 0:\n",
    "        # replace x2 and y2\n",
    "        y2 = bottom\n",
    "        x2 = int(x1 + (y2 - y1) / slope)\n",
    "        \n",
    "    return x1, y1, x2, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slope-Threshold Rejection\n",
    "Let's assume that a lane line is going to be within a narrow range of slopes.  That is to say, we're not going to have completely vertical lane lines (they'll be to one side or the other, we won't be driving on top of one) and we're not going to have completely horizontal lane lines (if we have somehow turned 90&deg; in our lane, we have bigger problems than lane line detection).\n",
    "\n",
    "Accordingly, let's see what that threshold might be, and reject Hough Transform-generated lines that are outside of that range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hough_lines(image, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    # Apply Canny Edge Detection\n",
    "    canny_image = canny(image, 255, 255)\n",
    "\n",
    "    # Mask the Region of Interest\n",
    "    vertices = np.array([[(100, 540), (440, 325), (520, 325), (900, 540)]])\n",
    "    masked_canny_image = region_of_interest(canny_image, vertices)\n",
    "\n",
    "    # Apply a Gaussian Noise filter\n",
    "    gaussian_image = gaussian_noise(masked_canny_image, 5)\n",
    "\n",
    "    # Find the Hough Lines\n",
    "    lines = cv2.HoughLinesP(gaussian_image, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_list = os.listdir(\"test_images/\")\n",
    "slopes = []\n",
    "for file in test_list:\n",
    "    if \"challenge\" in file:\n",
    "        continue\n",
    "    img = mpimg.imread('test_images/' + file)\n",
    "    \n",
    "    hough_lines = get_hough_lines(img, rho = 1, theta = np.pi / 180, threshold = 50,\n",
    "                          min_line_len = 100, max_line_gap = 150)\n",
    "    for line in hough_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slopes.append(abs((y2 - y1) / (x2 - x1)))\n",
    "\n",
    "plt.hist(slopes, bins = 20)\n",
    "plt.xlim(0,1)\n",
    "plt.xticks(np.arange(0, 1, 0.1))\n",
    "plt.title(\"Magnitude of Hough Transform-Generated Line Slopes\")\n",
    "plt.xlabel(\"Magnitude of Slope\\n(y2 - y1) / (x2 - x1)\")\n",
    "plt.ylabel(\"Frequency of Occurrence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it would seem that a sensible slope range would be **0.50 to 0.85**.\n",
    "\n",
    "Anything steeper or shallower is probably not a lane line, even though it is a line generated by the Hough Transform, and so we probably don't want to overlay it on our image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incorporating Slope Extension and Slope-Threshold Rejection\n",
    "Below is the pipeline from above, modified to include our new concepts of **slope extension** and **slope-threshold rejection**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_lines_to_bottom(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    Draws `lines` with `color` and `thickness`.\n",
    "    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    \"\"\"\n",
    "    if lines == None:\n",
    "        return\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            if 0.50 < abs(slope) < 0.85:\n",
    "                nx1, ny1, nx2, ny2 = toBottom(img.shape, x1, y1, x2, y2, slope)\n",
    "                cv2.line(img, (nx1, ny1), (nx2, ny2), color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hough_lines_to_bottom(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros(img.shape, dtype=np.uint8)\n",
    "    draw_lines_to_bottom(line_img, lines)\n",
    "    return line_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image_to_bottom(image):\n",
    "    # Apply the Canny Transform\n",
    "    canny_image = canny(image, 255, 255)\n",
    "\n",
    "    # Mask the Region of Interest\n",
    "    vertices = np.array([[(100, 540), (440, 325), (520, 325), (900, 540)]])\n",
    "    masked_canny_image = region_of_interest(canny_image, vertices)\n",
    "\n",
    "    # Apply a Gaussian Noise filter\n",
    "    gaussian_image = gaussian_noise(masked_canny_image, 5)\n",
    "\n",
    "    # Draw the Hough Lines\n",
    "    hough_image = hough_lines_to_bottom(gaussian_image, rho = 1, theta = np.pi / 180, threshold = 50,\n",
    "                          min_line_len = 100, max_line_gap = 150)\n",
    "\n",
    "    # Transform the hough_image into the same channel space.\n",
    "    # Or else, cv2.addWeighted will fail.\n",
    "    hough_image_BGR = cv2.cvtColor(hough_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Make the Hough Lines pink, because I like pink.\n",
    "    b,g,r = cv2.split(hough_image_BGR)\n",
    "    g = 0 * g\n",
    "    b * 0.5 * b\n",
    "    hough_image_pink = cv2.merge((b, g, r))\n",
    "    # See, e.g., http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.html\n",
    "\n",
    "    # Superimpose the Hough Lines on the original image\n",
    "    # Using the default parameters for α, β, and λ\n",
    "    superimposed_image = weighted_img(hough_image_pink, image, α=0.8, β=1., λ=0.1)\n",
    "\n",
    "    return superimposed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_list = os.listdir(\"test_images/\")\n",
    "for file in test_list:\n",
    "    if \"challenge\" in file:\n",
    "        continue\n",
    "    img = mpimg.imread('test_images/' + file)\n",
    "    print('This image is:', type(img), 'with dimensions:', img.shape)\n",
    "    after_img = process_image_to_bottom(img)\n",
    "    plt.figure()\n",
    "    plt.title(file)\n",
    "    plt.imshow(after_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image_to_bottom)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "Congratulations on finding the lane lines!  As the final step in this project, we would like you to share your thoughts on your lane finding pipeline... specifically, how could you imagine making your algorithm better / more robust?  Where will your current algorithm be likely to fail?\n",
    "\n",
    "Please add your thoughts below,  and if you're up for making your pipeline more robust, be sure to scroll down and check out the optional challenge video below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** ~~Should the lane lines be crossing over each other near the horizon?  If not, is the solution merely to shrink the Region of Interest?~~  \n",
    "\n",
    "   I noticed that the lane lines were crossing over each other near the horizon.  My solution for this was simply to lower the upper portion of the region of interest.\n",
    "\n",
    "**2.** ~~For striped lane markers, how can the Hough Lines be drawn so that they stretch to the bottom of the frame?~~  \n",
    "Previously, lane lines had gaps when the most recent stripe disappears, which isn't ideal.  The solution to this was to assume that, if a Hough line was found, then that line can be assumed to represent an unbroken lane line plane, and so can be extended to the bottom of the video frame.  \n",
    "\n",
    "   The issue with this assumpion is, of course, that it would incorrectly represent curves and turns, which would not be **linear** but rather **curvilinear**, perhaps best represented by a quadratic or other conic equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "If you're satisfied with your video outputs it's time to submit!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
